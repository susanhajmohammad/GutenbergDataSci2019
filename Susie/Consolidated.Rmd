---
title: "Consolidated"
author: "Susan Hajmohammad"
date: "April 24, 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(gutenbergr)
library(stringr)
library(dplyr)
library(tidyverse)
library(tidytext)
library(mosaic)
library(wordcloud)
library(RColorBrewer)
library(tm)

```


Download Northanger Abby from Gutenberger Package:

```{r}

north_abby <- gutenberg_download(121)

```

First, I used the gutenberg_download() function to download the Northanger abby text from http://www.gutenberg.org. 


Split up by chapter using a for loop:

```{r}

num_lines <- nrow(north_abby)

for (i in 1:num_lines) {
  
  north_abby$chapter[i] <- sum(str_detect(north_abby$text[1:i], pattern = fixed("CHAPTER"))) 
}


```

Select Chapter and Text:

```{r}

#north_abby <- as.matrix(north_abby)


abby_text <- north_abby %>%
  select(text, chapter)

```


Then I created another column called "chapter".  I used a for loop to count the number of "chapter"s written in the text. For every chapter word detected it counts as a TRUE and the chapter column is the sum of trues, therefore giving me the number of chapters.    



In order to str_detect() most accurately I had to break the text into words instead of observations. Using the unnest_tokens function I created a column "word" from the column "text" which used to be lines of text.   



Splitting novel up by words: 


```{r}

#library(tidytext)

abby_words <- abby_text%>%
  unnest_tokens(word, text)

```





In order to explore gothic words throughout the book, I first created a small word bank of words I thought represented a gothic theme.  By creating a function that uses sum() and str_detect() I was able to have an output that shows each word in the word back and gives the sum of how many times they are said in the book.  


Apply fuction on word bank: 

```{r}

word_bank <- c("murder", "dark", "scary", "ghost", "dead", "death", "scream", "blood", "frightened")


count_string <- function(x){
  sum(str_detect(abby_text$text, x))
  
}


sapply(word_bank, count_string)




```



By grouping the data set "abby_words" by chapter I was able to see the sum of a detected word by chapter. 




Words by chapter: 


```{r}

#library(tidyverse)

by_chap <- abby_text %>%
  group_by(chapter) %>%
  summarise(num_he = sum(str_detect(text, pattern = fixed(" he ", ignore_case = TRUE))))
  

by_chap


murder_chap <- abby_text %>%
  group_by(chapter) %>%
  summarise(num_he = sum(str_detect(text, pattern = fixed(" murder ", ignore_case = TRUE))))


murder_chap


dark_chap <- abby_text %>%
  group_by(chapter) %>%
  summarise(num_he = sum(str_detect(text, pattern = fixed(" dark ", ignore_case = TRUE))))


dark_chap


```




# Male Pronouns : he, him, his



```{r}

#head(abby_words)

# str_detect("he", regex("^he$"))
# 
# Don't do this for all of them only for the ones that are he, she etc. 



male_by_chap <- abby_words %>%
  group_by(chapter) %>%
  summarise(num_he = sum(str_detect(word, pattern = regex("^he$", ignore_case = TRUE))), 
            num_his = sum(str_detect(word, pattern = regex("^his$", ignore_case = TRUE))),
            num_him = sum(str_detect(word, pattern = regex("^him$", ignore_case = TRUE))))

```



I wanted to explore how much each gender was referenced throughout the book.  So, it was useful to be able to add the sums of detected words into one data frame.  This game me a cumulitive amount of how much certain words were referenced by chapter throughout the book. 


Cumulative male pronouns by chapter: 


```{r}

male_by_chap1 <- abby_words %>%
  group_by(chapter) %>%
  summarise(num_male = sum(str_detect(word, pattern = regex("^he$", ignore_case = TRUE))) 
            + sum(str_detect(word, pattern = regex("^his$", ignore_case = TRUE)))
            + sum(str_detect(word, pattern = regex("^him$", ignore_case = TRUE))))

sum(male_by_chap)




```

I created a visualtion of the data set that included the culumative number of male pronouns by chapter. Gf_smooth() shows a more general trend of the amounts of male pronouns per chapter.  


```{r}

#library(mosaic)

gf_smooth(num_male ~ chapter, data = male_by_chap1) + geom_line()

gf_smooth(num_him ~ chapter, data = male_by_chap) + geom_line()

```

THe trend of male pronouns fluctuates rapidly throughout the book.  There are large spikes from chapter 10 and on.  
 
 
 
I used the same functions to find the trend of female pronouns throughout the book.  
 
 
# Female Pronouns : she, her, hers


Cumulative female pronouns by chapter: 


```{r}

female_by_chap1 <- abby_words %>%
  group_by(chapter) %>%
  summarise(num_female = sum(str_detect(word, pattern = regex("^she$", ignore_case = TRUE))) 
            + sum(str_detect(word, pattern = regex("^her$", ignore_case = TRUE)))
            + sum(str_detect(word, pattern = regex("^hers$", ignore_case = TRUE))))

sum(female_by_chap1)




```

There are a lot more female pronouns referenced throughout the book.  THe max is about 160 in one chapter, while for male pronouns seemed to max out at about 25 in one chapter.  

```{r}

#library(mosaic)


gf_smooth(num_female ~ chapter, data = female_by_chap1) + geom_line()


```





To look at both of these graphs in one visual, I combined the graphs by adding each line.  I separated them by color.  The red line represents female pronouns and the green line represents male pronouns.  


Visualization of both gender pronouns: 

```{r}


female_by_chap2 <- female_by_chap1%>%
  select(num_female)

gender_by_chap <- cbind(female_by_chap2, male_by_chap1)




require(ggplot2)

ggplot(gender_by_chap, aes(x = chapter)) +                    
  geom_line(aes(y= num_female), colour="red") + 
  geom_line(aes(y= num_male), colour="green")  

```

The spikes of each line seem to mimic each other, meaning the amount of pronouns in each chapter seem to fluctuate similarly. 



I created a word cloud to explore with words were most frequently said throughout the entire book.  


Word cloud of most frequent words:


```{r, warning=FALSE}

abby_t <- north_abby$text


abby_corp <- Corpus(VectorSource(abby_t))
  

abby_corp <- tm_map(abby_corp, removeWords, stopwords("english"))


tdm <- TermDocumentMatrix(abby_corp)

abby_m <- as.matrix(tdm)


abby_v <- sort(rowSums(abby_m), decreasing = TRUE)

abby_df <- data.frame(word = names(abby_v), freq = abby_v)


head(abby_df)




# library("wordcloud")
# library("RColorBrewer")


set.seed(1234)

wordcloud(words = abby_df$word, freq = abby_df$freq, min.freq = 1, max.words = 100, random.order = FALSE, rot.per = 0.35, colors = brewer.pal(8, "RdYlGn"))





```

This word cloud has both a size and color scale.  The larger the word the more frequently it was said.  Green words were said most frequently while red words were written least frequently.  I used an already made wordbank of "stopwords" "stopwords("english")"; however, this word bank apparently didn't include a very common stop word "the".  


I looked up the main characters in Northanger abby on Spark Notes. This website also told me other names that characters were called. I found the amount of times each of the most popular characters were referenced per chapter.  There were certain characters I avoided using in this because their names were two words and the data set I created only has one word per observation.  

Main Characters in Northanger abby <https://www.sparknotes.com/lit/northangerabbey/characters/>


Catherine Morland: Catherine

```{r}


cath_by_chap <- abby_words %>%
  group_by(chapter) %>%
  summarise(num_cath = sum(str_detect(word, pattern = regex("^catherine$", ignore_case = TRUE))) 
            + sum(str_detect(word, pattern = regex("^catherine's$", ignore_case = TRUE))))

sum(cath_by_chap)




```



Henry Tilney: Henry


```{r}


hen_by_chap <- abby_words %>%
  group_by(chapter) %>%
  summarise(num_hen = sum(str_detect(word, pattern = regex("^henry$", ignore_case = TRUE))) 
            + sum(str_detect(word, pattern = regex("^henry's$", ignore_case = TRUE))))

sum(hen_by_chap)




```


Eleanor Tilney: Eleanor


```{r}


el_by_chap <- abby_words %>%
  group_by(chapter) %>%
  summarise(num_el = sum(str_detect(word, pattern = regex("^eleanor$", ignore_case = TRUE))) 
            + sum(str_detect(word, pattern = regex("^eleanor's$", ignore_case = TRUE))))

sum(el_by_chap)


```



General Tilney: General


```{r}


gen_by_chap <- abby_words %>%
  group_by(chapter) %>%
  summarise(num_gen = sum(str_detect(word, pattern = regex("^general$", ignore_case = TRUE))) 
            + sum(str_detect(word, pattern = regex("^general's$", ignore_case = TRUE))))

sum(gen_by_chap)


```


Isabella Thorpe: Isabella


```{r}


isa_by_chap <- abby_words %>%
  group_by(chapter) %>%
  summarise(num_isa = sum(str_detect(word, pattern = regex("^isabella$", ignore_case = TRUE))) 
            + sum(str_detect(word, pattern = regex("^isabella's$", ignore_case = TRUE))))

sum(isa_by_chap)


```


John Thorpe: John

```{r}

john_by_chap <- abby_words %>%
  group_by(chapter) %>%
  summarise(num_john = sum(str_detect(word, pattern = regex("^john$", ignore_case = TRUE))) 
            + sum(str_detect(word, pattern = regex("^john's$", ignore_case = TRUE))))

sum(john_by_chap)





```


James Morland: James


```{r}

jam_by_chap <- abby_words %>%
  group_by(chapter) %>%
  summarise(num_jam = sum(str_detect(word, pattern = regex("^james$", ignore_case = TRUE))) 
            + sum(str_detect(word, pattern = regex("^james's$", ignore_case = TRUE))))

sum(jam_by_chap)





```


Frederick Tilney: Frederick, Captain Tilney


```{r}

fred_by_chap <- abby_words %>%
  group_by(chapter) %>%
  summarise(num_fred = sum(str_detect(word, pattern = regex("^frederick$", ignore_case = TRUE))) 
            + sum(str_detect(word, pattern = regex("^frederick's$", ignore_case = TRUE)))  
            + sum(str_detect(word, pattern = regex("^captain$", ignore_case = TRUE)))
             + sum(str_detect(word, pattern = regex("^captain's$", ignore_case = TRUE))))

sum(fred_by_chap)





```



These characters are harder because they have to words that are necessary to identify the character.  


Mrs. Thorpe: Mrs. Thorpe


Mr. And Mrs. Allen: Mr. Allen, Mrs. Allen


Mr. And Mrs. Morland And Family: Mrs. Morland, Mr. Morland, family



The numbers of how much a character was referenced are not entirely accurate.  This is because a character could be referenced more formally like Miss Thorpe instead of isabella. 



It would be too much to have data from all the characters represented on one graph.  So I decided to create two graphs: One with Catherine and female characters and the other was Catherine compared to male characters. 



# Catherine and other female characters: 



```{r}


isa_by_chap1 <- isa_by_chap%>%
  select(num_isa)

el_by_chap1 <- el_by_chap%>%
  select(num_el)

cath_fem <- cbind(cath_by_chap, isa_by_chap1, el_by_chap1)

require(ggplot2)

ggplot(cath_fem, aes(x = chapter)) +                    
  geom_line(aes(y= num_cath), colour="red") + 
  geom_line(aes(y= num_isa), colour="green") +
  geom_line(aes(y= num_el), colour="blue")

```

Catherine is referenced more generally per chapter, except for some instances like in chapter about 18-19 isabella seems to make more of an appearance, and in the later chapters elanor seems to come in as a very contributing character. 

# Catherine and other male characters: 



```{r}
hen_by_chap1 <- hen_by_chap%>%
  select(num_hen)

fred_by_chap1 <- fred_by_chap%>%
  select(num_fred)


jam_by_chap1 <- jam_by_chap%>%
  select(num_jam)


john_by_chap1 <- john_by_chap%>%
  select(num_john)

gen_by_chap1 <- gen_by_chap%>%
  select(num_gen)

cath_male <- cbind(cath_by_chap, hen_by_chap1, fred_by_chap1, jam_by_chap1, john_by_chap1, gen_by_chap1)

require(ggplot2)

ggplot(cath_male, aes(x = chapter)) +                    
  geom_line(aes(y= num_cath), colour="red") + 
  geom_line(aes(y= num_hen), colour="green") +
  geom_line(aes(y= num_fred), colour="blue") +
  geom_line(aes(y= num_jam), colour="yellow") +
  geom_line(aes(y= num_john), colour="orange") +
  geom_line(aes(y= num_gen), colour="purple")

```


Again, Catherine is referenced more than other characters.  Of the male characters, General and Henry seem to be the more main male characters.  

