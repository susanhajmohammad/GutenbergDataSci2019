---
title: "Consolidated"
author: "Susan Hajmohammad"
date: "April 24, 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(gutenbergr)
library(stringr)
library(dplyr)
library(tidyverse)
library(tidytext)
library(mosaic)
library(wordcloud)
library(RColorBrewer)

```


Download Northanger Abby from Gutenberger Package:

```{r}

north_abby <- gutenberg_download(121)

```



Split up by chapter using a for loop:

```{r}

num_lines <- nrow(north_abby)

for (i in 1:num_lines) {
  
  north_abby$chapter[i] <- sum(str_detect(north_abby$text[1:i], pattern = fixed("CHAPTER"))) 
}


```

Select Chapter and Text:

```{r}

#north_abby <- as.matrix(north_abby)


abby_text <- north_abby %>%
  select(text, chapter)

```


Splitting novel up by words: 


```{r}

#library(tidytext)

abby_words <- abby_text%>%
  unnest_tokens(word, text)

```



Apply fuction on word bank: 

```{r}

word_bank <- c("murder", "dark", "scary", "ghost", "dead", "death", "scream", "blood", "frightened")


count_string <- function(x){
  sum(str_detect(abby_text$text, x))
  
}


sapply(word_bank, count_string)




```

Words by chapter: 


```{r}

#library(tidyverse)

by_chap <- abby_text %>%
  group_by(chapter) %>%
  summarise(num_he = sum(str_detect(text, pattern = fixed(" he ", ignore_case = TRUE))))
  

by_chap


murder_chap <- abby_text %>%
  group_by(chapter) %>%
  summarise(num_he = sum(str_detect(text, pattern = fixed(" murder ", ignore_case = TRUE))))


murder_chap


dark_chap <- abby_text %>%
  group_by(chapter) %>%
  summarise(num_he = sum(str_detect(text, pattern = fixed(" dark ", ignore_case = TRUE))))


dark_chap


```





```{r}

word_by_chap <- abby_text %>%
  group_by(chapter) %>%
  summarise(num_he = sum(str_detect(text, pattern = fixed(" he ", ignore_case = TRUE))), num_murder = sum(str_detect(text, pattern = fixed(" murder", ignore_case = TRUE))), num_dark = sum(str_detect(text, pattern = fixed(" dark", ignore_case = TRUE))))



```


```{r}

#library(mosaic)


gf_smooth(num_he ~ chapter, data = word_by_chap) + geom_line()


```



```{r}


by_chap <- abby_text %>%
  group_by(chapter) %>%
  summarise(num_he_him = sum(str_detect(text, pattern = fixed(" he ", ignore_case = TRUE)) | str_detect(text, pattern = fixed(" him ", ignore_case = TRUE))))


```

Word cloud of most frequent words:


```{r}

abby_t <- north_abby$text


abby_corp <- Corpus(VectorSource(abby_t))
  

abby_corp <- tm_map(abby_corp, removeWords, stopwords("english"))


tdm <- TermDocumentMatrix(abby_corp)

abby_m <- as.matrix(tdm)


abby_v <- sort(rowSums(abby_m), decreasing = TRUE)

abby_df <- data.frame(word = names(abby_v), freq = abby_v)


head(abby_df)




# library("wordcloud")
# library("RColorBrewer")


set.seed(1234)

wordcloud(words = abby_df$word, freq = abby_df$freq, min.freq = 1, max.words = 100, random.order = FALSE, rot.per = 0.35, colors = brewer.pal(8, "RdYlGn"))





```


