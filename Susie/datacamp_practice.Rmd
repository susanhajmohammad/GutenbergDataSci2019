---
title: "datacamp practice on books"
author: "Susan Hajmohammad"
date: "April 4, 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}

library(gutenbergr)
library(stringr)
library(dplyr)



```

```{r}

north_abby <- gutenberg_download(121)


```


Split up by chapter:

Use a for loop:

```{r}

num_lines <- nrow(north_abby)

for (i in 1:num_lines) {
  
  north_abby$chapter[i] <- sum(str_detect(north_abby$text[1:i], pattern = fixed("CHAPTER"))) 
  
  
}




```

```{r}



#north_abby <- as.matrix(north_abby)


abby_text <- north_abby %>%
  select(text, chapter)

```






```{r}

#north_abby$chapter <- str_detect(north_abby, pattern = "chapter")



contains_ss <- str_detect(north_abby, pattern = fixed("ss"))

contains_ss

sum(contains_ss)

north_abby[contains_ss]

```



Practice word bank :
murder 
dark 
scary
ghost
dead
death
scream
blood
frightened



apply fuction 
on word bank 

```{r}

word_bank <- c("murder", "dark", "scary", "ghost", "dead", "death", "scream", "blood", "frightened")

# spooky_words <- str_detect(abby_text, pattern = c("murder", "dark", "scary", "ghost", "dead", "death", "scream", "blood", "frightened"))
# 
# sum(spooky_words)


spooky_words <- str_detect(abby_text, pattern = c("dark", "frightened"))

#xx <- lapply(spooky_words, str_detect())


dark <- str_detect(abby_text, pattern = "dark")

sum(dark)


frightened <- str_detect(abby_text, pattern = "frightened")

sum(frightened)




```


Create function: 



```{r}



count_string <- function(x){
  sum(str_detect(abby_text$text, x))
  
}


sapply(word_bank, count_string)

  
```







```{r}

  
  

# number_dark <- str_count(north_abby, pattern = "dark")
# 
# hist(number_dark)



murder <- str_detect(abby_text, pattern = "murder")

sum(murder)


scary <- str_detect(abby_text, pattern = "scary")

sum(scary)


ghost <- str_detect(abby_text, pattern = "ghost")

sum(ghost)


dead <- str_detect(abby_text, pattern = "dead")

sum(dead)


death <- str_detect(north_abby, pattern = "death")

sum(death)

scream <- str_detect(north_abby, pattern = "scream")

sum(scream)


blood <- str_detect(north_abby, pattern = "blood")

sum(blood)


```



character presence:


```{r}

Catherine <- str_detect(north_abby, pattern = "Catherine")

sum(Catherine)


```


```{r}

James <- str_detect(north_abby, pattern = "James")

sum(James)


```


He vs. She


```{r}

#abby_text <- as.matrix(abby_text)

he <- str_detect(abby_text, pattern = "he")

sum(he)


```

He by Chapter:


```{r}

library(tidyverse)

by_chap <- abby_text %>%
  group_by(chapter) %>%
  summarise(num_he = sum(str_detect(text, pattern = fixed(" he ", ignore_case = TRUE))))
  

by_chap


murder_chap <- abby_text %>%
  group_by(chapter) %>%
  summarise(num_he = sum(str_detect(text, pattern = fixed(" murder ", ignore_case = TRUE))))


murder_chap

  





```










```{r}

she <- str_detect(north_abby, pattern = "she")

sum(she)


```


There are four female characters and 6 male characters according to wiki <https://en.wikipedia.org/wiki/Northanger_Abbey#Characters>


Using str_split

```{r}


north_abby1 <- str_split(north_abby, pattern = fixed(" . "), simplify = TRUE)


head(north_abby1)



```



```{r}

library(rebus)

of <- char_class("of")

of

str_view(north_abby, pattern = of)



```


## Sentiment Anlysis: the tidy way:

Lexicons:

```{r}

library(dplyr)
library(tidytext)

get_sentiments("bing")





```




Splitting novel up by words: 


```{r}


library(tidytext)


abby_words <- abby_text%>%
  unnest_tokens(word, text)


```


Practice visualizing the word frequencies:



```{r}

# library(tm)
# #convert north_abby to a matrix
# 
# 
# abby_source <- VectorSource(north_abby$text)
# 
# abby_tdm <- TermDocumentMatrix(abby_words)
# 
# #check tdm help file google
# 
# abby_m <- as.matrix(abby_words)
# 
# 
# #sum rows and sort by frquency
# 
# term_frequency <- rowSums(abby_m)
# term_frequency <- sort(term_frequency, decreasing = TRUE)
# 
# 
# #Create a bar plot
# 
# barplot(term_frequency[1:10], col = "tan", las = 2)





```






```{r}


library(qdap)



```


Making a word cloud:


1. put txt file as a corpus

```{r}

abby_t <- north_abby$text

```


```{r}
library(tm)

abby_corp <- Corpus(VectorSource(abby_t))
  
  
```



To remove common english stop words: 



```{r}


abby_corp <- tm_map(abby_corp, removeWords, stopwords("english"))



```





Build a term - document matrix:

```{r}

tdm <- TermDocumentMatrix(abby_corp)

abby_m <- as.matrix(tdm)



```


sum the rows and sort by frequency:


```{r}

abby_v <- sort(rowSums(abby_m), decreasing = TRUE)

abby_df <- data.frame(word = names(abby_v), freq = abby_v)


head(abby_df)

```


Generate a word cloud:

words	= the words

freq = their frequencies

min.freq = words with frequency below min.freq will not be plotted

max.words	= Maximum number of words to be plotted. least frequent terms dropped

random.order = plot words in random order. If false, they will be plotted in decreasing frequency

rot.per	= proportion words with 90 degree rotation

colors = color words from least to most frequent


```{r}


library("wordcloud")
library("RColorBrewer")


set.seed(1234)

wordcloud(words = abby_df$word, freq = abby_df$freq, min.freq = 1, max.words = 100, random.order = FALSE, rot.per = 0.35, colors = brewer.pal(8, "RdYlGn"))





```



Per line

```{r}


by_chap <- abby_text %>%
  group_by(chapter) %>%
  summarise(num_he_him = sum(str_detect(text, pattern = fixed(" he ", ignore_case = TRUE)) | 
                               str_detect(text, pattern = fixed(" him ", ignore_case = TRUE))| 
                               str_detect(text, pattern = fixed(" his ", ignore_case = TRUE))))


```





word cloud:

<http://www.sthda.com/english/wiki/text-mining-and-word-cloud-fundamentals-in-r-5-simple-steps-you-should-know>


color options: 

<https://www.rdocumentation.org/packages/RColorBrewer/versions/1.1-2/topics/RColorBrewer>

display.brewer.all()


two graphs in one:

<https://stackoverflow.com/questions/2564258/plot-two-graphs-in-same-plot-in-r>

