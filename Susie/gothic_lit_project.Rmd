---
title: "Gothic Literature Analysis in R"
author: "Susan Hajmohammad"
date: "February 13, 2019"
output: html_document
---

```{r setup, include=FALSE}

library(dplyr)
library(gutenbergr)
library(tm)
library(tidytext)
library(stringr)
library(tidyr)
library(topicmodels)
library(ggplot2)
library(tidytext)
library(openNLP)

library(openNLPmodels.en)


library(XML)
library(tm)
library(tm.plugin.webmining)
#library(tm.plugin.sentiment)
library(NLP)
library(openNLP)
stock <-"JPM"
library(quanteda)

library(readtext)

# corpus <- WebCorpus(GoogleFinanceSource(stock))
# sentences <- sentDetect(corpus)



```
 

### Downloading what Gothic books we have access to from the meta data
 
 
```{r}


gb <- gutenberg_metadata




goth_books <- gb %>%
 select(gutenberg_id, title, author, gutenberg_author_id, language, gutenberg_bookshelf, rights, has_text) %>%   
 filter(str_detect(str_to_lower(gutenberg_bookshelf), "gothic"))



goth_en <- goth_books %>%
  filter(language == "en")


```
 
 
### A count for how many of the Gothic books in our dataframe each other has written. 
 
 
```{r}

## both these codes do the same thing 

goth_en %>%
  count(author)


goth_en %>% 
  group_by(author)%>%
  summarize(Num = n())





```
 
### Downloading the texts from our previous dataframe and adding a column for Title and Chapter.   
 
```{r}


goth_texts <- gutenberg_download(goth_en, meta_fields = "title")


goth_by_chapter <- goth_texts %>%
  group_by(title) %>%
  mutate(chapter = cumsum(str_detect(text, regex("^chapter ", ignore_case = TRUE)))) %>%
  ungroup() %>%
  filter(chapter > 0)


```
 
 
### Counting the amount of sentences by counting the number of "."s 
 
```{r}



got <- goth_by_chapter %>%
  group_by(title, chapter) %>%
  count(".")

a_book <- gutenberg_download(42, meta_fields = "title")

a_book %>%
  count(".")

```
 
 
 
### FInding average word length  
 
 
```{r}




words <- str_split(a_book, " ")
words_ <- lapply(words, length)  #this is number of words in a chapter. 
word_lengths <- lapply(words, str_length)
lapply(word_lengths, mean)

##creates a list, make so that it works for a data frame




###write_csv




```
 
 
### Counting words per chapter or words per line

```{r}
words <- str_split(a_book, " ")
words_ <- lapply(words, length)



```

 
 
 
```{r}

goth_by_chapter_word <- goth_by_chapter %>%
  unite(title_chapter, title, chapter) %>%
  unnest_tokens(word, text)

word_counts <- goth_by_chapter_word %>%
  anti_join(stop_words) %>%
  count(title_chapter, word, sort = TRUE)


#add in arrange by capter title. 

word_counts

```
 
 

 


